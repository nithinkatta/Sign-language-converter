
<h1>Sign Language Conveter</h1>
<h3>Description </h3>

The project uses Python, MediaPipe, OpenCV, and Gemini AI to develop a real-time sign language-to-text and speech generation system. MediaPipe recognizes hand gestures, and OpenCV processes real-time input. Gemini AI corrects sentence formation. Together, they create a seamless communication channel between sign language and spoken language users. The dataset, likely containing annotated images or videos with diverse sign language gestures, trains the model to recognize and interpret signs accurately. Python is the primary programming language, offering flexibility and ease of integration with MediaPipe and OpenCV. This project showcases the synergy between these tools, providing an inclusive solution for bridging communication gaps.
> **Background**:Dumb or autistic people always face difficulty in expressing their feelings as they can only communicate in sign language which is not understandable by others. Our project is an intermediate between them. 

<br/> 

## Tech Stack used ‚ú®
- **TensorFlow**: used to model the dataset [click here to know more](https://www.tensorflow.org) <img src="https://github.com/google/mediapipe/assets/48355572/5205ea50-174c-4bb3-b2e9-b4564ad1a9c7" height="35.5px">
- **Mediapipe**: collects landmarks and helps in identifying the gesture. [Tap to get the repo](https://github.com/googlesamples/mediapipe)
  <p align="center"><img src="VirtualConnect%208b1efe88061b4234946400cc0b8beed5/VirtualConnect_c5ea835e103249a3a7bf94e229d80a04Untitled_1.png" ></p>
- **Gemini**:We have used an API from Gemini to correct the sentences.(we have prompted for this api in Gemini) which enrichens our project.
 <p align="center"> <img src="VirtualConnect%208b1efe88061b4234946400cc0b8beed5/VirtualConnect_c5ea835e103249a3a7bf94e229d80a04Untitled_2.png" ></p>
<li><b>gTTS</b>: A Python library which converts text to speech</li> 
<li> <b>Teachable Machine</b>: Used in modeling the dataset.<p align="center"> <img src="VirtualConnect%208b1efe88061b4234946400cc0b8beed5/VirtualConnect_c5ea835e103249a3a7bf94e229d80a04Untitled_4.png" alt="f"  height="200px"/><p/>
 
  

#### üî∏ Demo Video ‚Üí [**Here**](https://www.youtube.com/watch?v=Ul29OHtsRBs) ‚ú®
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|


## Normal scenario ‚ö†Ô∏è
<p align="center"><img src="VirtualConnect%208b1efe88061b4234946400cc0b8beed5/VirtualConnect_c5ea835e103249a3a7bf94e229d80a04Untitled_5.png" alt="f" margin="100000000px" width="500"/></p>

 



<h1><b>When our project comes into the picture‚ú®</b></h1>   

Helps in easy conversion
![Untitled](VirtualConnect%208b1efe88061b4234946400cc0b8beed5/Untitled.png)

# Project working flowchart

![Untitled](VirtualConnect%208b1efe88061b4234946400cc0b8beed5/Untitled%201.png)

<br/>
>  A webcam is essential & required for hand detection and gesture recognition. Please ensure your device has a functioning webcam.

<br/>

![dotted-bar-long](https://user-images.githubusercontent.com/48355572/263612162-32246a50-238b-48d7-aa6d-f1562b04ce3a.png)

<br/>

  





</ul>
